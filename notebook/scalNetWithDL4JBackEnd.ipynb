{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import via maven des différentes dépendances:\n",
    "Il est à savoir que pour scalnet, il est nécessaire d'utiliser la version alpha pour avoir directement dans le modèle l'évaluation et l'accuracy. \n",
    "Par contre pour nd4j, la version 0.9.1 est nécésaire pour éviter les problèmes de dépendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.deeplearning4j deeplearning4j-core 0.9.1\n",
    "org.deeplearning4j scalnet_2.11 1.0.0-alpha\n",
    "org.nd4j nd4j-native-platform 0.9.1\n",
    "org.nd4j nd4s_2.11 0.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des packages utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\r\n",
       "import org.deeplearning4j.optimize.listeners.ScoreIterationListener\r\n",
       "import org.deeplearning4j.scalnet.layers.core.Dense\r\n",
       "import org.deeplearning4j.scalnet.models.Sequential\r\n",
       "import org.deeplearning4j.scalnet.regularizers.L2\r\n",
       "import org.nd4j.linalg.activations.Activation\r\n",
       "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator\r\n",
       "import org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener\n",
    "import org.deeplearning4j.scalnet.layers.core.Dense\n",
    "import org.deeplearning4j.scalnet.models.Sequential\n",
    "import org.deeplearning4j.scalnet.regularizers.L2\n",
    "import org.nd4j.linalg.activations.Activation\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer dataSet:\n",
    "Dans cette partie, on va importer les données  mnist (écriture de chiffre à la main) et de faire notre apprentissage avec ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@5ef89a99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val batchSize: Int = 64\n",
    "val seed: Int = 28\n",
    "val mnistTrain: DataSetIterator = new MnistDataSetIterator(batchSize, true, seed)\n",
    "val mnistTest: DataSetIterator = new MnistDataSetIterator(batchSize, false, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation:\n",
    "Dans cette partie, nous allons construire un modèle PMC (perceptron multi-couche) pour prédire les divers images d'écriture de chiffre manuscrite labéliser de 1 à 9. Pour cela, on va utiliser un modèle séquentiel à deux couches cachées et de taille 512 chacun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Taille d'une image\n",
    "val height: Int = 28\n",
    "val width: Int = 28\n",
    "// Nombre de classe dont on dispose\n",
    "val nClasses: Int = 10\n",
    "\n",
    "// nombre de neurone dans chaque couche cachée\n",
    "val hiddenSize = 512\n",
    "// taux d'apprentissage et decay\n",
    "val learningRate: Double = 0.001\n",
    "val decay: Double = 0.005\n",
    "\n",
    "val model: Sequential = Sequential(rngSeed = seed)\n",
    "\n",
    "model.add(Dense(hiddenSize, height * width, activation = Activation.RELU, regularizer = L2(learningRate * decay)))\n",
    "model.add(Dense(hiddenSize, activation = Activation.RELU, regularizer = L2(learningRate * decay)))\n",
    "model.add(Dense(nClasses, activation = Activation.SOFTMAX, regularizer = L2(learningRate * decay)))\n",
    "model.compile(LossFunction.NEGATIVELOGLIKELIHOOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val scoreFrequency:Int = 1000\n",
    "val epochs: Int = 30\n",
    "model.fit(mnistTrain, epochs, List(new ScoreIterationListener(scoreFrequency)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de notre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 1.0\n",
      "Test accuracy = 0.9825\n"
     ]
    }
   ],
   "source": [
    "println(s\"Train accuracy = ${model.evaluate(mnistTrain).accuracy}\")\n",
    "println(s\"Test accuracy = ${model.evaluate(mnistTest).accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "La première partie de cette tutoriel a pour objectif de comprendre comment on lance un modèle PMC sur scala.Comme on peut le voir, on a bien réussi cette partie. \n",
    "scalnet est l'équivalent de keras sur python. Donc ce qu'il y a en backend est DL4J qui est un peu plus compliqué d'utilisation comme tensorflow sur python. Les divers paramètres du modèle n'a pas été détaillé ici.Mais encore, l'objectif est déjà de pouvoir trouver les bonnes dépendances nécéssaires pour qu'on puisse lancer des modèles de deep-learning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
